---
title: "Supplement"
subtitle: "Technical Note: Curve fitting algorithm for multimodal particle size distributions â€“ a theoretical basis"
author: Christopher Rapp
date: "2025-07-22"
output:
  bookdown::pdf_document2: default
  bookdown::word_document2: default
  bookdown::html_document2: default
linkcolor: blue
---

Source code for SMPS read functions are housed here <https://github.com/christopher-rapp/scripts-multimodal.git>

### Retrieve Read Functions

```{r, echo = FALSE, message = FALSE}

devtools::source_url("https://raw.githubusercontent.com/christopher-rapp/scripts-multimodal/refs/heads/main/functions_multimodal_V2.R")

devtools::source_url("https://raw.githubusercontent.com/christopher-rapp/scripts-multimodal/refs/heads/main/readPSD_BMI.R")

devtools::source_url("https://raw.githubusercontent.com/christopher-rapp/scripts-multimodal/refs/heads/main/readPSD_NAS.R")

devtools::source_url("https://raw.githubusercontent.com/christopher-rapp/scripts-multimodal/refs/heads/main/readPSD_NC.R")

devtools::source_url("https://raw.githubusercontent.com/christopher-rapp/scripts-multimodal/refs/heads/main/readPSD_TSI.R")

```

### Import Libraries

```{r}

library(stringr)
library(data.table)
library(tidyr)
library(dplyr)
library(lubridate)
library(logr)
library(ggplot2)
library(purrr)
library(patchwork)
library(ncdf4)
```

### Brechtel Manufacturing Inc. (BMI) Data

```{r}

# Path to data
import.path = '/Users/christopherrapp/Library/CloudStorage/Box-Box/Multimodal Curve Fitting/example/BMI/'

BMI.data.ls <- readPSD_BMI(import.path, tz = "US/Eastern")

# Read functions export data as a list to account for multiple files in a directory
dataPSD.BMI <- BMI.data.ls[[1]]

head(dataPSD.BMI)
```

### TSI Data

Use example data from Storm Peak Laboratory for a new particle formation event (NPF) on 2022-03-23 MDT.

```{r}

import.path = '/Users/christopherrapp/Library/CloudStorage/Box-Box/Multimodal Curve Fitting/example/TSI/'

TSI.data.ls <- readPSD_TSI(import.path, tz = "US/Mountain")

# Read functions export data as a list to account for multiple files in a directory
dataPSD.TSI <- TSI.data.ls[[1]]

head(dataPSD.TSI)
```

### netCDF Data

```{r}

import.path = '/Users/christopherrapp/Library/CloudStorage/Box-Box/Multimodal Curve Fitting/example/netCDF/'

NC.data.ls <- readPSD_NC(import.path)

# Read functions export data as a list to account for multiple files in a directory
dataPSD.NC <- NC.data.ls[[1]]

head(dataPSD.NC)
```

### NASA-AMES Data

```{r}

import.path = '/Users/christopherrapp/Library/CloudStorage/Box-Box/Multimodal Curve Fitting/example/NASA-AMES/'

NAS.data.ls <- readPSD_NAS(import.path)

# Read functions export data as a list to account for multiple files in a directory
dataPSD.NAS <- NAS.data.ls[[1]]

head(dataPSD.NAS)

```

## Running multimodal

```{r, fig.width = 8, fig.height = 8, fig.align = "center", echo=FALSE}

# Frequency is null here because I already grouped data above
tmp <- multimodal.fitting(dataPSD.BMI,
          log.path = '~/Library/CloudStorage/Box-Box/Multimodal Curve Fitting/log/',
          frequency = NULL,
          labeling = T,
          max.iterations = 20,
          max.modes = 6,
          lower.limit = 10,
          upper.limit = 1500,
          NMRSE.threshold = 0.05,
          FVU.threshold = 20,
          verbose = F)

tmp

```

```{r, fig.width = 8, fig.height = 8, fig.align = "center", echo=FALSE}

# Frequency is null here because I already grouped data above
tmp <- multimodal.fitting(dataPSD.TSI,
          log.path = '~/Library/CloudStorage/Box-Box/Multimodal Curve Fitting/log/',
          frequency = NULL,
          labeling = T,
          max.iterations = 20,
          max.modes = 6,
          lower.limit = 10,
          upper.limit = 1500,
          NMRSE.threshold = 0.05,
          FVU.threshold = 20,
          verbose = T)
```

Notice the failure message? This is because the dataset begins for bin diameter 9.14. Now we can retry with adjusted limits.

```{r, fig.width = 8, fig.height = 8, fig.align = "center", echo=FALSE}

# Frequency is null here because I already grouped data above
tmp <- multimodal.fitting(dataPSD.TSI,
          log.path = '~/Library/CloudStorage/Box-Box/Multimodal Curve Fitting/log/',
          frequency = NULL,
          labeling = T,
          max.iterations = 20,
          max.modes = 6,
          lower.limit = 8,
          upper.limit = 1500,
          NMRSE.threshold = 0.05,
          FVU.threshold = 20,
          verbose = T)

tmp

```

For this file there is a NPF event, but currently the averaging across the entire day removes all temporal variation. We will instead select times between 07:00 and 15:00 and use an hourly frequency.

```{r, fig.width = 8, fig.height = 8, fig.align = "center", echo=FALSE}

data <- subset(dataPSD.TSI, dataPSD.TSI$`Local Time` >= as.POSIXct("2022-03-23 7:00:00") &
                 dataPSD.TSI$`Local Time` <= as.POSIXct("2022-03-23 15:00:00"))

# Frequency is null here because I already grouped data above
tmp <- multimodal.fitting(data,
          log.path = '~/Library/CloudStorage/Box-Box/Multimodal Curve Fitting/log/',
          frequency = 60, # number of minutes
          labeling = T,
          max.iterations = 20,
          max.modes = 10,
          lower.limit = 8,
          upper.limit = 1500,
          NMRSE.threshold = 0.05,
          FVU.threshold = 20,
          verbose = F)

map(tmp, 2)

```

Note - for features

```{r, fig.width = 8, fig.height = 8, fig.align = "center", echo=FALSE}

data <- subset(dataPSD.TSI, dataPSD.TSI$`Local Time` >= as.POSIXct("2022-03-23 10:00:00") &
                 dataPSD.TSI$`Local Time` <= as.POSIXct("2022-03-23 10:15:00"))

# Frequency is null here because I already grouped data above
tmp <- multimodal.fitting(data,
          log.path = '~/Library/CloudStorage/Box-Box/Multimodal Curve Fitting/log/',
          frequency = 1, # number of minutes
          labeling = T,
          max.iterations = 20,
          max.modes = 10,
          lower.limit = 8,
          upper.limit = 1500,
          NMRSE.threshold = 0.05,
          FVU.threshold = 20,
          verbose = F)

map(tmp, 2)
```
